{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"16.TensorFlow 分布式訓練.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNQaanq052JPzoozFXHU3bE"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CNjWbeopjNSm","colab_type":"text"},"source":["**單機多卡訓練： MirroredStrategy**\n","\n","tf.distribute.MirroredStrategy 是一種簡單且高性能的，資料並行的同步式分散式策略，主要支援多個 GPU 在同一台主機上訓練。使用這種策略時，我們只需實例化一個 MirroredStrategy 策略:\n","\n","strategy = tf.distribute.MirroredStrategy()"]},{"cell_type":"markdown","metadata":{"id":"7iflLRlojUgE","colab_type":"text"},"source":["以下程式碼展示了使用 MirroredStrategy 策略，在 TensorFlow Datasets 中的部分圖像資料集上使用 Keras 訓練 MobileNetV2 的過程："]},{"cell_type":"code","metadata":{"id":"oHJMIU7BjVT0","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","\n","num_epochs = 5\n","batch_size_per_replica = 64\n","learning_rate = 0.001\n","\n","strategy = tf.distribute.MirroredStrategy()\n","print('Number of devices: %d' % strategy.num_replicas_in_sync)  # 輸出設備數量\n","batch_size = batch_size_per_replica * strategy.num_replicas_in_sync\n","\n","# 載入資料集並預處理\n","def resize(image, label):\n","    image = tf.image.resize(image, [224, 224]) / 255.0\n","    return image, label\n","\n","# 使用 TensorFlow Datasets 載入貓狗分類資料集，詳見“TensorFlow Datasets資料集載入”一章\n","dataset = tfds.load(\"cats_vs_dogs\", split=tfds.Split.TRAIN, as_supervised=True)\n","dataset = dataset.map(resize).shuffle(1024).batch(batch_size)\n","\n","with strategy.scope():\n","    model = tf.keras.applications.MobileNetV2()\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","        loss=tf.keras.losses.sparse_categorical_crossentropy,\n","        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n","    )\n","\n","model.fit(dataset, epochs=num_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"osuxDb5ljcp8","colab_type":"text"},"source":["**多機訓練： MultiWorkerMirroredStrategy**\n","\n","多機訓練的方法和單機多卡類似，將 MirroredStrategy 更換為適合多機訓練的 MultiWorkerMirroredStrategy 即可。不過，由於涉及到多台電腦之間的通訊，還需要進行一些額外的設置。具體而言，需要設置環境變數 TF_CONFIG ，範例如下:\n","\n","os.environ['TF_CONFIG'] = json.dumps({\n","    'cluster': {\n","        'worker': [\"localhost:20000\", \"localhost:20001\"]\n","    },\n","    'task': {'type': 'worker', 'index': 0}\n","})"]},{"cell_type":"markdown","metadata":{"id":"ia5spzhejhuM","colab_type":"text"},"source":["以下範例的訓練任務與之前章節相同，只不過遷移到了多機訓練環境。假設我們有兩台機器，即首先在兩台機器上均部署下面的程式，唯一的區別是 task 部分，第一台機器設置為 {'type': 'worker', 'index': 0} ，第二台機器設置為 {'type': 'worker', 'index': 1} 。接下來，在兩台機器上依序執行程式，待通訊成功後，即會自動開始訓練流程。"]},{"cell_type":"code","metadata":{"id":"oDTuzFdMjh1D","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import os\n","import json\n","\n","num_epochs = 5\n","batch_size_per_replica = 64\n","learning_rate = 0.001\n","\n","num_workers = 2\n","os.environ['TF_CONFIG'] = json.dumps({\n","    'cluster': {\n","        'worker': [\"localhost:20000\", \"localhost:20001\"]\n","    },\n","    'task': {'type': 'worker', 'index': 0}\n","})\n","strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n","batch_size = batch_size_per_replica * num_workers\n","\n","def resize(image, label):\n","    image = tf.image.resize(image, [224, 224]) / 255.0\n","    return image, label\n","\n","dataset = tfds.load(\"cats_vs_dogs\", split=tfds.Split.TRAIN, as_supervised=True)\n","dataset = dataset.map(resize).shuffle(1024).batch(batch_size)\n","\n","with strategy.scope():\n","    model = tf.keras.applications.MobileNetV2()\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","        loss=tf.keras.losses.sparse_categorical_crossentropy,\n","        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n","    )\n","\n","model.fit(dataset, epochs=num_epochs)"],"execution_count":null,"outputs":[]}]}