{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8.Keras Pipeline *.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMub/dtYFaamNdFMGSHHDvl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sZuDetXJb8HR"},"source":["**Keras Sequential/Functional API 模式建立模型**\n","\n","最典型和常用的神經網路結構是將一堆層按特定順序疊加起來，那麼，我們是不是只需要提供一個層的列表，就能由 Keras 將它們自動首尾相連，形成模型呢？Keras 的 Sequential API 正是如此。通過向 tf.keras.models.Sequential() 提供一個層的列表，就能快速地建立一個 tf.keras.Model 模型並返回："]},{"cell_type":"code","metadata":{"id":"1aQAJ5muSJq-","executionInfo":{"status":"ok","timestamp":1601211525346,"user_tz":-480,"elapsed":856,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["import tensorflow as tf\n","import numpy as np\n","\n","class MNISTLoader():\n","    def __init__(self):\n","        mnist = tf.keras.datasets.mnist\n","        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n","        # MNIST中的圖片預設為uint8（0-255的數字）。以下程式碼將其正規化到0-1之間的浮點數，並在最後增加一維作為顏色通道\n","        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 28, 28, 1]\n","        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 28, 28, 1]\n","        self.train_label = self.train_label.astype(np.int32)    # [60000]\n","        self.test_label = self.test_label.astype(np.int32)      # [10000]\n","        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n","\n","    def get_batch(self, batch_size):\n","        # 從資料集中隨機取出batch_size個元素並返回\n","        index = np.random.randint(0, self.num_train_data, batch_size)\n","        return self.train_data[index, :], self.train_label[index]\n","\n","num_epochs = 5\n","batch_size = 50\n","learning_rate = 0.001"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkSMbcyFb8OX","executionInfo":{"status":"ok","timestamp":1601211525348,"user_tz":-480,"elapsed":838,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["#1.繼承keras.Model, call()定義任意複雜的網路結構\n","#2.keras.Model構造函數, 傳入inputs和outputs, 定義任意複雜的網路結構\n","#3.keras.models.Sequential(), 只能定義簡單的1層傳1層的網路結構\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n","    tf.keras.layers.Dense(10),\n","    tf.keras.layers.Softmax()\n","])"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UvVgkS8ecEcV"},"source":["不過，這種層疊結構並不能表示任意的神經網路結構。為此，Keras 提供了 Functional API，幫助我們建立更為複雜的模型，例如多輸入 / 輸出或存在參數共用的模型。其使用方法是將層作為可調用的對象並返回張量（這點與之前章節的使用方法一致），並將輸入向量和輸出向量提供給 tf.keras.Model 的 inputs 和 outputs 參數，範例如下："]},{"cell_type":"code","metadata":{"id":"natwrUa0cEiN","executionInfo":{"status":"ok","timestamp":1601211525349,"user_tz":-480,"elapsed":832,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["#更靈活的模型結構定義方式\n","# inputs = tf.keras.Input(shape=(28, 28, 1))\n","# x = tf.keras.layers.Flatten()(inputs)\n","# x = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)(x)\n","# x = tf.keras.layers.Dense(units=10)(x)\n","# outputs = tf.keras.layers.Softmax()(x)\n","# model = tf.keras.Model(inputs=inputs, outputs=outputs)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EjT7y1YZcQZl"},"source":["**使用 Keras Model 的 compile 、 fit 和 evaluate 方法訓練和評估模型**\n","\n","當模型建立完成後，通過 tf.keras.Model 的 compile 方法配置訓練過程："]},{"cell_type":"code","metadata":{"id":"GQuQEjm7cG9F","executionInfo":{"status":"ok","timestamp":1601211525349,"user_tz":-480,"elapsed":825,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss=tf.keras.losses.sparse_categorical_crossentropy,\n","    metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",")"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"hq7nzxLiSrXJ","executionInfo":{"status":"ok","timestamp":1601211545236,"user_tz":-480,"elapsed":20705,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}},"outputId":"8450d592-bff7-4979-e867-b9efadccb473","colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["data_loader = MNISTLoader()\n","\n","model.fit(data_loader.train_data, data_loader.train_label, epochs=num_epochs, batch_size=batch_size)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1200/1200 [==============================] - 4s 3ms/step - loss: 0.3065 - sparse_categorical_accuracy: 0.9138\n","Epoch 2/5\n","1200/1200 [==============================] - 3s 3ms/step - loss: 0.1418 - sparse_categorical_accuracy: 0.9593\n","Epoch 3/5\n","1200/1200 [==============================] - 4s 4ms/step - loss: 0.1025 - sparse_categorical_accuracy: 0.9705\n","Epoch 4/5\n","1200/1200 [==============================] - 4s 4ms/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9768\n","Epoch 5/5\n","1200/1200 [==============================] - 3s 2ms/step - loss: 0.0622 - sparse_categorical_accuracy: 0.9815\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fba247647b8>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"SWPJqIinTq_D","executionInfo":{"status":"ok","timestamp":1601211545973,"user_tz":-480,"elapsed":21432,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}},"outputId":"da8e3ec6-44c6-4910-b5cf-f8e7caf4d02e","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(model.evaluate(data_loader.test_data, data_loader.test_label))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 0s 1ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9727\n","[0.09186572581529617, 0.9726999998092651]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U-Rgk6YEce7S"},"source":["**自定義層、損失函數和評量指標**\n","\n","可能你還會問，如果現有的這些層無法滿足我的要求，我需要定義自己的層怎麼辦？事實上，我們不僅可以繼承 tf.keras.Model 編寫自己的模型類，也可以繼承 tf.keras.layers.Layer 編寫自己的層。\n","\n","**自定義層**\n","\n","自定義層需要繼承 tf.keras.layers.Layer 類，並覆寫 __init__ 、 build 和 call 三個方法，如下所示："]},{"cell_type":"code","metadata":{"id":"5XyOHaqccfDb","executionInfo":{"status":"ok","timestamp":1601211545974,"user_tz":-480,"elapsed":21424,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["class MyLayer(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super().__init__()\n","        # 初始化程式碼\n","\n","    def build(self, input_shape):     # input_shape 是一個 TensorShape 類型對象，提供輸入的形狀\n","        # 在第一次使用該層的時候呼叫該部分程式碼，在這裡創建變數可以使得變數的形狀自適應輸入\n","        # 而不需要使用者額外指定變數形狀。\n","        # 如果已經可以完全確定變數的形狀，也可以在__init__部分創建變數\n","        self.variable_0 = self.add_weight(...)\n","        self.variable_1 = self.add_weight(...)\n","\n","    def call(self, inputs):\n","        # 模型呼叫的程式碼（處理輸入並返回輸出）\n","        return output"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"02fmL8bSctv7"},"source":["例如，如果我們要自己實現一個 本章第一節 中的全連接層（ tf.keras.layers.Dense ），可以按以下方式編寫。此程式碼在 build 方法中創建兩個變數，並在 call 方法中使用創建的變數進行運算："]},{"cell_type":"code","metadata":{"id":"fnsJT_chct3h","executionInfo":{"status":"ok","timestamp":1601211545975,"user_tz":-480,"elapsed":21418,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["class MNISTLoader():\n","    def __init__(self):\n","        mnist = tf.keras.datasets.mnist\n","        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n","        # MNIST中的圖片預設為uint8（0-255的數字）。以下程式碼將其正規化到0-1之間的浮點數，並在最後增加一維作為顏色通道\n","        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 28, 28, 1]\n","        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 28, 28, 1]\n","        self.train_label = self.train_label.astype(np.int32)    # [60000]\n","        self.test_label = self.test_label.astype(np.int32)      # [10000]\n","        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n","\n","    def get_batch(self, batch_size):\n","        # 從資料集中隨機取出batch_size個元素並返回\n","        index = np.random.randint(0, self.num_train_data, batch_size)\n","        return self.train_data[index, :], self.train_label[index]\n","\n","num_epochs = 5\n","batch_size = 50\n","learning_rate = 0.001\n","\n","class LinearLayer(tf.keras.layers.Layer):\n","    def __init__(self, units):\n","        super().__init__()\n","        self.units = units\n","\n","    def build(self, input_shape):     # 這裡 input_shape 是第一次運行call()時參數inputs的形狀\n","        self.w = self.add_variable(name='w',\n","            shape=[input_shape[-1], self.units], initializer=tf.random_normal_initializer())\n","        self.b = self.add_variable(name='b',\n","            shape=[self.units], initializer=tf.random_normal_initializer())\n","\n","    def call(self, inputs):\n","        y_pred = tf.nn.relu(tf.matmul(inputs, self.w) + self.b)\n","        return y_pred\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Flatten(),\n","    LinearLayer(100),\n","    LinearLayer(10),\n","    tf.keras.layers.Softmax()\n","])"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cllhqL24cxI3"},"source":["在定義模型的時候，我們便可以如同 Keras 中的其他層一樣，呼叫我們自定義的層 LinearLayer："]},{"cell_type":"code","metadata":{"id":"LhcSuAabcxPu","executionInfo":{"status":"ok","timestamp":1601211545976,"user_tz":-480,"elapsed":21413,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["class LinearModel(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.layer = LinearLayer(units=1)\n","\n","    def call(self, inputs):\n","        output = self.layer(inputs)\n","        return output"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vOUuBvykc2tv"},"source":["**自定義損失函數和評量指標**\n"," \n","自定義損失函數需要繼承 tf.keras.losses.Loss 類別，重寫 call 方法即可，輸入真實值 y_true 和模型預測值 y_pred ，輸出模型預測值和真實值之間通過自定義的損失函數計算出的損失值。下面的範例為均方差 (Mean-Square Error, MSE）損失函數："]},{"cell_type":"code","metadata":{"id":"iGlwvJISc2zn","executionInfo":{"status":"ok","timestamp":1601211545976,"user_tz":-480,"elapsed":21404,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["class MeanSquaredError(tf.keras.losses.Loss):\n","    def call(self, y_true, y_pred):\n","        y_true = tf.one_hot(tf.cast(y_true, dtype='int32'), depth=10)\n","        return tf.reduce_mean(tf.reduce_sum(tf.square(y_pred - y_true)))\n","\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss=MeanSquaredError(),\n","    metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",")\n","\n","data_loader = MNISTLoader()\n","\n","model.fit(data_loader.train_data, data_loader.train_label, epochs=num_epochs, batch_size=batch_size)"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SrfckHLHc6X3"},"source":["自定義評量指標需要繼承 tf.keras.metrics.Metric 類，並重寫 __init__ 、 update_state 和 result 三個方法。下面的範例對前面用到的 SparseCategoricalAccuracy 評量指標類別做了一個簡單的重實現："]},{"cell_type":"code","metadata":{"id":"8kWEYnrNc6e-","executionInfo":{"status":"ok","timestamp":1601211545977,"user_tz":-480,"elapsed":21398,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["class SparseCategoricalAccuracy(tf.keras.metrics.Metric):\n","    def __init__(self):\n","        super().__init__()\n","        self.total = self.add_weight(name='total', dtype=tf.int32, initializer=tf.zeros_initializer())\n","        self.count = self.add_weight(name='count', dtype=tf.int32, initializer=tf.zeros_initializer())\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        values = tf.cast(tf.equal(y_true, tf.argmax(y_pred, axis=-1, output_type=tf.int32)), tf.int32)\n","        self.total.assign_add(tf.shape(y_true)[0])\n","        self.count.assign_add(tf.reduce_sum(values))\n","\n","    def result(self):\n","        return self.count / self.total"],"execution_count":29,"outputs":[]}]}