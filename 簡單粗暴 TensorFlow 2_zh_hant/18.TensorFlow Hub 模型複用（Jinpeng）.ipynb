{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"18.TensorFlow Hub 模型複用（Jinpeng）.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNb0d7gedcl262wgKb/lHkx"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"iGPz6A__t4Jy"},"source":["**TensorFlow Hub 模型複用（Jinpeng）**\n","\n","在軟體開發中，我們經常複用開源軟體或開源函式庫，避免相同功能的程式碼重複開發，減少了大量的重複勞動，也有效縮短了軟體開發周期。程式碼複用，對軟體產業的發展，有著極大的幫助。\n","\n","相對的，TF Hub 目的是為了更好的複用已訓練好且經過充分驗證的模型，可節省大量的訓練時間和計算資源。這些預訓練好的模型，可以進行直接部署，也可以進行遷移學習（Transfer Learning）。對獨立開發者來說，TF Hub 是非常有意義的，他們可以快速複用像谷歌這樣的大公司使用大量計算資源訓練的模型，而他們個人去蒐集這些資源是很不實際的。"]},{"cell_type":"markdown","metadata":{"id":"9H91dZ2ruAHp"},"source":["**TF Hub 安裝**\n","\n","TF Hub 是單獨的一個函式庫，需要單獨安裝，安裝指令如下："]},{"cell_type":"code","metadata":{"id":"rjGrsQxzt4UZ"},"source":["!pip install tensorflow-hub"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5nRXX_yAuGih"},"source":["**TF Hub 模型使用案例**\n","\n","TF Hub 模型的複用非常簡單，程式碼如下："]},{"cell_type":"code","metadata":{"id":"6Fgwxmq6uGop"},"source":["import tensorflow_hub as hub\n","\n","hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n","hub_model = hub.load(hub_handle)\n","outputs = hub_model(inputs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-x6jbYb7uOXm"},"source":["根據 stylization 模型的參考程式碼和 notebook，進行了精簡和修改，實作出圖像的風格轉換功能。"]},{"cell_type":"code","metadata":{"id":"1TQFz7iBuOd2"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","def crop_center(image):\n","    \"\"\"Returns a cropped square image.\"\"\"\n","    shape = image.shape\n","    new_shape = min(shape[1], shape[2])\n","    offset_y = max(shape[1] - shape[2], 0) // 2\n","    offset_x = max(shape[2] - shape[1], 0) // 2\n","    image = tf.image.crop_to_bounding_box(image, offset_y, offset_x, new_shape, new_shape)\n","    return image\n","\n","def load_image_local(image_path, image_size=(512, 512), preserve_aspect_ratio=True):\n","    \"\"\"Loads and preprocesses images.\"\"\"\n","    # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n","    img = plt.imread(image_path).astype(np.float32)[np.newaxis, ...]\n","    if img.max() > 1.0:\n","        img = img / 255.\n","    if len(img.shape) == 3:\n","        img = tf.stack([img, img, img], axis=-1)\n","    img = crop_center(img)\n","    img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n","    return img\n","\n","def show_image(image, title, save=False, fig_dpi=300):\n","    plt.imshow(image, aspect='equal')\n","    plt.axis('off')\n","    if save:\n","        plt.savefig(title + '.png', bbox_inches='tight', dpi=fig_dpi,pad_inches=0.0)\n","    else:\n","        plt.show()\n","\n","content_image_path = \"images/contentimg.jpeg\"\n","style_image_path = \"images/styleimg.jpeg\"\n","\n","content_image = load_image_local(content_image_path)\n","style_image = load_image_local(style_image_path)\n","\n","show_image(content_image[0], \"Content Image\")\n","show_image(style_image[0], \"Style Image\")\n","\n","# Load image stylization module.\n","hub_module = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2');\n","\n","# Stylize image.\n","outputs = hub_module(tf.constant(content_image), tf.constant(style_image))\n","stylized_image = outputs[0]\n","\n","show_image(stylized_image[0], \"Stylized Image\", True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RJy6A-jguWBu"},"source":["**TF Hub 模型 Retrain 範例**\n","\n","相信預預訓練的模型不一定能滿足開發者的實際需求，還需要進行二次訓練。針對這種情況，TF Hub 提供了很方便的 Keras 接口 hub.KerasLayer(url) ，可以封裝在 Keras 的 Sequential 層狀結構中，進而針對開發者的需求和資料進行再訓練。\n","\n","我們以 inception_v3 的模型為例，簡單介紹 ``hub.KerasLayer (url)`` 使用的方法："]},{"cell_type":"code","metadata":{"id":"OUUVx0NkuWLO"},"source":["import tensorflow_hub as hub\n","\n","num_classes = 10\n","\n","# 使用 hub.KerasLayer 組件待訓練模型\n","new_model = tf.keras.Sequential([\n","    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\", output_shape=[2048], trainable=False),\n","    tf.keras.layers.Dense(num_classes, activation='softmax')\n","])\n","new_model.build([None, 299, 299, 3])\n","\n","# 輸出模型結構\n","new_model.summary()"],"execution_count":null,"outputs":[]}]}